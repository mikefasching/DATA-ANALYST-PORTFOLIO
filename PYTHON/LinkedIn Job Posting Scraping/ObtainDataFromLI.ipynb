{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d728870b-0a18-4cef-9d1a-82dde3fa235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33715aa9-45ff-497b-9222-06bfbe8b091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log in to LinkedIn to access data\n",
    "def login(driver):\n",
    "    url = \"https://www.linkedin.com/checkpoint/rm/sign-in-another-account?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin\"\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(url)\n",
    "\n",
    "    username = driver.find_element_by_id(\"username\")\n",
    "    password = driver.find_element_by_id(\"password\")\n",
    "    username.send_keys(\"????\")    #USERNAME to LI\n",
    "    password.send_keys(\"????\")    #PASSWORD to LI\n",
    "\n",
    "def search(driver):\n",
    "    time.sleep(20)\n",
    "    driver.get(\"https://www.linkedin.com/jobs/search/?keywords=data%20scientist&location=New%20York%2C%20United%20States\")\n",
    "\n",
    "#grabs results fetched\n",
    "def get_n_results(driver):\n",
    "  time.sleep(2)\n",
    "  results_div = driver.find_element_by_xpath('//*[@id=\"main\"]/div/div[2]/div[1]/header/div[1]/small/div/span')\n",
    "  n_string = results_div.text\n",
    "  n = int(n_string.split()[0].replace(',',\"\"))\n",
    "  return n \n",
    "\n",
    "#Finds job ul div\n",
    "def get_jobs(driver):\n",
    "  ul_div = driver.find_element_by_xpath(\"//main[@id='main']//ul[1]\")\n",
    "  return ul_div\n",
    "    \n",
    "#Scrolls to properly load page\n",
    "def scroll_down(driver):\n",
    "    time.sleep(2)\n",
    "    element = driver.find_element_by_xpath('//*[@id=\"main\"]/div/div[2]/div[1]/div')\n",
    "    scroll_height = element.get_property(\"scrollHeight\")\n",
    "\n",
    "    # Set the scroll step and delay between steps\n",
    "    scroll_step = 150\n",
    "    delay = 0.1\n",
    "\n",
    "    current_scroll = 0\n",
    "    while current_scroll < scroll_height:\n",
    "        driver.execute_script(\"arguments[0].scrollTo(0, arguments[1]);\", element, current_scroll)\n",
    "        time.sleep(delay)\n",
    "        current_scroll += scroll_step\n",
    "\n",
    "    # Wait for a short period for the new content to load\n",
    "    time.sleep(2)\n",
    "      \n",
    "def get_job_urls(jobs,driver,job_urls = {}):\n",
    "  i = 1\n",
    "  #Collects job urls,location role cand company \n",
    "  #the final result updates the input dictionary and appends a key value pair with the format\n",
    "  #    url:{'company':company,'location':location,'role':role}\n",
    "  while True: \n",
    "    try:\n",
    "        WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH,f\"//main[@id='main']//ul[1]\")))\n",
    "        url = jobs.find_element_by_xpath(f\"//main[@id='main']//ul[1]//li[{i}]//a[1]\").get_attribute(\"href\")\n",
    "        role = jobs.find_element_by_xpath(f\"//main[@id='main']//ul[1]//li[{i}]//a[1]\").text\n",
    "        company = jobs.find_element_by_xpath(f\"//main[@id='main']//ul[1]//li[{i}]//div[1]//div[1]//div[1]//div[2]//div[2]//span[1]\").text\n",
    "        location = driver.find_element_by_xpath(f\"//main[@id='main']//ul[1]//li[{i}]//li[1]\").text\n",
    "        job_urls.update({url:{'company':company,'location':location,'role':role}})\n",
    "        i+=1\n",
    "    except:\n",
    "        return job_urls\n",
    "\n",
    "def load_next_page(driver):\n",
    "  #loads next page for url retrival\n",
    "  curr= driver.find_element_by_xpath('//*[@aria-current=\"true\"]').text\n",
    "  next = driver.find_element_by_xpath(f'//*[@aria-label=\"Page {int(curr)+1}\"]')\n",
    "  next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d74f1130-3290-4913-bbfe-ef81faf13089",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@aria-label=\"Page 11\"]\"}\n  (Session info: chrome=123.0.6312.123)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m jobs \u001b[38;5;241m=\u001b[39m get_jobs(driver)\n\u001b[0;32m     14\u001b[0m get_job_urls(jobs,driver,job_urls \u001b[38;5;241m=\u001b[39m job_dict)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mload_next_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 68\u001b[0m, in \u001b[0;36mload_next_page\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_next_page\u001b[39m(driver):\n\u001b[0;32m     66\u001b[0m   \u001b[38;5;66;03m#loads next page for url retrival\u001b[39;00m\n\u001b[0;32m     67\u001b[0m   curr\u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element_by_xpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//*[@aria-current=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 68\u001b[0m   \u001b[38;5;28mnext\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element_by_xpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//*[@aria-label=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPage \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:394\u001b[0m, in \u001b[0;36mWebDriver.find_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_element_by_xpath\u001b[39m(\u001b[38;5;28mself\u001b[39m, xpath):\n\u001b[0;32m    379\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m    Finds an element by xpath.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m        element = driver.find_element_by_xpath('//div/td[1]')\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:976\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m         by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    975\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    323\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@aria-label=\"Page 11\"]\"}\n  (Session info: chrome=123.0.6312.123)\n"
     ]
    }
   ],
   "source": [
    "# Run theough the entire process of fetch in urls logining in and grabing job descriptions\n",
    "driver = webdriver.Chrome(r'C:\\Program Files\\Google\\Chrome\\Application\\chromedriver.exe')\n",
    "login(driver)\n",
    "search(driver)\n",
    "n = get_n_results(driver)\n",
    "if n > 350: #makes sure only 350 or less job openings are scraped (too much time otherwise)\n",
    "    n = 350\n",
    "pages = int(n/25)\n",
    "job_dict ={}\n",
    "#iterate through the amount of pages given\n",
    "for i in range(pages):\n",
    "  scroll_down(driver)\n",
    "  jobs = get_jobs(driver)\n",
    "  get_job_urls(jobs,driver,job_urls = job_dict)\n",
    "  load_next_page(driver)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83de3191-e077-436b-8008-8289dd691fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(driver, job_dict):\n",
    "    fail = []\n",
    "    # Iterate through the url list to scrape the descriptions\n",
    "    for url in list(job_dict.keys()):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            if driver.current_url != url:\n",
    "                print(f'failed at {url}')\n",
    "                # remove broken urls\n",
    "                job_dict.pop(url)\n",
    "            # scrape\n",
    "            applicants_str = driver.find_element_by_xpath(\"//*[self::span or self::strong][contains(text(), 'applicant') or contains(text(), 'applicants')]\").text\n",
    "            applicant_num = int(''.join(filter(str.isdigit, applicants_str)))\n",
    "            \n",
    "            post_dates = driver.find_elements_by_xpath(\"//*[contains(text(), 'ago')]\")\n",
    "            for post_date in post_dates:\n",
    "                text = post_date.text\n",
    "                post_date_days = re.search(r'(\\d+)\\s+(month|week|day|hour|minute|second)s?\\s+ago', text)\n",
    "                if post_date_days:\n",
    "                    value = int(post_date_days.group(1))\n",
    "                    unit = post_date_days.group(2)\n",
    "            \n",
    "                    if unit == \"month\":\n",
    "                        value *= 30\n",
    "                    elif unit == \"week\":\n",
    "                        value *= 7\n",
    "                    elif unit in [\"day\", \"hour\", \"minute\", \"second\"]:\n",
    "                        # Handle other units as needed\n",
    "                        pass\n",
    "                \n",
    "            description_element = driver.find_element_by_xpath(\"//h2[text()='About the job']/parent::div\")\n",
    "            description = description_element.get_attribute(\"textContent\")\n",
    "            job_dict.get(url).update({\"applicants\": applicant_num, \"description\": description, \"post_days\": value})\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {url}: {str(e)}\")\n",
    "            fail.append(url)\n",
    "    return job_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2575f10-64f9-4728-9917-5068a11636b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing https://www.linkedin.com/jobs/view/3491768450/?eBP=CwEAAAGO5JyRhI9HQg2alAUDByfOooc6AVeVV2ObWzfMmVwbEaei3Hp9_FLzgPc2uXfxQU2oRhcNuUCwPn0KuxAY48tpUZgInORWqHyjVnt6jcEJIUlUvGJKrrs8uwg3fzrhyX1k-e5vZurxItcZETvnzI03g2Y2ZvnX55T-HTlImMsvM_ouK-uOvHiMX2HHDHJThqyGPYRP0OcoQZJFvV3JMIzc25BkYBQsNqv2wqhKDvOoSOVkTBhd9YkO3_dDPX1pIdB9BuwAhjD8VxjuQjSc_6oF5rJtwtn37Dol0gdfIvNy_ybZL89RiSQTKFpnmThZ0_kA47tQuj1DDrvLkAeADv-z6d97dYs&refId=e3AQ%2F3F0mwn5XBTQMVmxgQ%3D%3D&trackingId=4Ns9P1RA%2Fp7bdQbUKhv1Mg%3D%3D&trk=flagship3_search_srp_jobs: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[self::span or self::strong][contains(text(), 'applicant') or contains(text(), 'applicants')]\"}\n",
      "  (Session info: chrome=123.0.6312.123)\n",
      "\n",
      "An error occurred while processing https://www.linkedin.com/jobs/view/3575088349/?eBP=CwEAAAGO5JyRhDHQs4vtuacCjdzaYQHWw9_XtVkwDZ7uQKk40a-QfEcMy5mLHxqBoIMl-RngVbnofxJgv6ZNmnFHWdvcBmUmw7jRidD4Iqpngd80hk-_NML3kMJS-yRnN4yMkW7xQ6bZtEVYSqWckmWvFO8tm73VYuST7NIdOvWvljQ3C5uhNPMcr5511CaTIlvpauVX__RxOKfZ88XdcRA0truBZz8q_aHoubgxB_Th2qUPM_x71ZEmFMirYjXAkC2exd_cFXFYvssgu-2SZcz3FG0n6BelPb5UwaIAgw2HYC8nQHursfmovTCNvh7kkznnfQEKPTBn7UPwTnyHSNnqeWjxjUrWJ4w&refId=e3AQ%2F3F0mwn5XBTQMVmxgQ%3D%3D&trackingId=jJzmqbxiyXtPmNDDW5eaWg%3D%3D&trk=flagship3_search_srp_jobs: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[self::span or self::strong][contains(text(), 'applicant') or contains(text(), 'applicants')]\"}\n",
      "  (Session info: chrome=123.0.6312.123)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_dict = get_description(driver,job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b9b7a2f-8a84-4727-9ae1-74a24a3763e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict to CSV\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as a string\n",
    "datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Append the formatted date and time to the original filename\n",
    "filename = f\"job_data_scientist_NYC_{datetime_string}.csv\"# Specify the file path and filename \n",
    "\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writerow(['url', 'company', 'location', 'role', 'description', 'applicants','post_days'])\n",
    "    \n",
    "    # Write the data row\n",
    "    for url, data in job_dict.items():\n",
    "        row = [url] + [data.get(key, '') for key in ['company', 'location', 'role', 'description', 'applicants','post_days']]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec072ed8-5e93-4f6e-922e-4c8a8b2d82d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
